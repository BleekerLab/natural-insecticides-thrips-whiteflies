{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import random \n",
    "\n",
    "# custom functions\n",
    "from helper_functions import extract_feature_importance_avg_and_sd_from_multiple_random_forest_runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"pheno_terpenoids.tsv\",sep=\"\\t\",index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get the X and y arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get whitefly classes\n",
    "y = df[\"wf\"].tolist()\n",
    "stratify_info = df['wf'].map({'non-toxic': 0, 'toxic': 1})\n",
    "\n",
    "# get matrix X of volatile values\n",
    "X = df.iloc[:,2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract feature importance from the RF runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generates a list with two elements\n",
    "# first element average feature importance\n",
    "# and second element standard deviation\n",
    "feature_importances = extract_feature_importance_avg_and_sd_from_multiple_random_forest_runs(\n",
    "    X,\n",
    "    y,\n",
    "    nb_of_splits=6,\n",
    "    nb_of_trees=1000,\n",
    "    nb_of_runs=5,\n",
    "    njobs=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine the average en std deviations \n",
    "mean_varimportance = feature_importances[0].mean(axis=1)\n",
    "\n",
    "# sum the variances (=squared std) and then take the mean\n",
    "pooled_std = np.sqrt((feature_importances[1]**2).mean(axis=1))\n",
    "\n",
    "# create panda for convenience\n",
    "yerr = pd.concat([mean_varimportance-2*pooled_std, mean_varimportance,mean_varimportance+2*pooled_std],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the variable importances for each run and compare them to each other -> gives idea of stability \n",
    "#sns.pairplot(data=feature_importances[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permutations to extract p-values for each feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import extract_feature_importances_from_random_forests_on_permuted_y\n",
    "\n",
    "# compute feature importances based on permuted y values\n",
    "feature_importance_perm = extract_feature_importances_from_random_forests_on_permuted_y(\n",
    "    X,\n",
    "    y,\n",
    "    nb_of_splits=6,\n",
    "    nb_of_trees=1000,\n",
    "    nperm=5,\n",
    "    njobs=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate p-values\n",
    "\n",
    "**How?** By comparing the average feature importance from the original dataset to the distribution of feature importance based on N permutations.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import get_significant_features\n",
    "\n",
    "signif = get_significant_features(X,\n",
    "                                  original_feature_importances=feature_importances,\n",
    "                                  permuted_feature_importances=feature_importance_perm,\n",
    "                                  pval=0.05)\n",
    "signif.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(signif.iloc[:,0].astype('float'),20)\n",
    "plt.title('Distribution of observed p-values');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot of the original mean & sd versus the permuted distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mysel = pvalues.loc[pvalues.iloc[:,0]<(0.05/X.shape[0]),:].sort_values('p-value')\n",
    "mysel = signif.loc[signif.iloc[:,0]<0.05,:].sort_values('p-value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only select those variables that have p-value smaller than 0.05 (after bonferroni correction)\n",
    "#mysel = pvalues.loc[pvalues.iloc[:,0]<(0.05/X.shape[0]),:].sort_values('p-value')\n",
    "#mysel = signif.loc[signif.iloc[:,0]<0.05,:].sort_values('p-value')\n",
    "\n",
    "# plot those variables\n",
    "nrplots = len(mysel.index.values)\n",
    "fig = plt.figure(figsize=([3,12]),dpi=150)\n",
    "ax = fig.subplots(nrows=nrplots,ncols=1)\n",
    "\n",
    "yerr = pd.concat([mean_varimportance-2*pooled_std, mean_varimportance,mean_varimportance+2*pooled_std],axis=1)\n",
    "\n",
    "for i in range(nrplots):                \n",
    "    plt.subplot(ax[i])\n",
    "    sns.distplot(feature_importance_perm.iloc[mysel.index.values[i],:],bins=10,ax=ax[i])\n",
    "    plt.plot(mi[mysel.index.values[i]],0,mi[mysel.index.values[i]],50,'o')\n",
    "    plt.plot(yerr.iloc[mysel.index.values[i],0],0,yerr.iloc[mysel.index.values[i],0],50,'^')\n",
    "    plt.plot(yerr.iloc[mysel.index.values[i],2],0,yerr.iloc[mysel.index.values[i],2],50,'v')\n",
    "\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write final results to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here an extra check.. set p-value < 0.05 AND rsd < 0.25 \n",
    "\n",
    "adf = pd.concat([pvalues,pooled_std,mean_varimportance,pooled_std/mean_varimportance],axis=1)\n",
    "adf.rename(columns={0:'std',1:'avg',2:'rsd'},inplace=True);\n",
    "signif = adf.loc[adf['p-value'] < 0.05]\n",
    "print(signif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.iloc[:,signif.index.values]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sort dataframe by phenotypic class\n",
    "To display a heatmap that shows the rows of the non-toxic genotypes followed by the rows of the toxic genotypes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted = df.sort_values(by=[\"wf\"])\n",
    "\n",
    "# make a new column containing the accession and phenotypic class\n",
    "df_sorted[\"genotypes and class\"] = df_sorted.index.values + \"_\" + df_sorted[\"wf\"]\n",
    "df_sorted = df_sorted.set_index(df_sorted[\"genotypes and class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X matrix similar to the one used for the Random Forest analysis (rows are reordered, not columns)\n",
    "X = df_sorted.iloc[:,2:]\n",
    "\n",
    "# add one for log offset\n",
    "X_disp = X.replace(0,1) \n",
    "\n",
    "# display heatmap of log2(values)\n",
    "log_function = lambda x: np.log2(x)\n",
    "sns.heatmap(X_disp.iloc[:,signif.index.values].apply(log_function),cmap=\"Blues\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter to keep only significant metabolites\n",
    "X_filt = X.iloc[:,signif.index.values]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make plots for each candidate summing over the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert a column with the genotype + class\n",
    "X_filt.insert(loc=0,column=\"id\",value=X_filt.index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new data frame with split value columns \n",
    "new = X_filt[\"id\"].str.split(\"_\", n = 1, expand = True) \n",
    "  \n",
    "# making separate last name column from new data frame \n",
    "X_filt.loc[:,\"wf\"]= new[1]\n",
    "\n",
    "# add index column\n",
    "X_filt = X_filt.set_index(\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic = X_filt.iloc[:,0:-1][X_filt[\"wf\"] == \"toxic\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nontoxic = X_filt.iloc[:,0:-1][X_filt[\"wf\"] == \"non-toxic\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare a dataframe for plotting\n",
    "sumByClass = pd.DataFrame({'toxic':toxic, 'non-toxic':nontoxic})\n",
    "sumByClass = sumByClass.reset_index()\n",
    "sumByClass.columns.values[0]=\"candidate\"\n",
    "sumByClass = sumByClass.melt(id_vars=\"candidate\",var_name=\"class\",value_name=\"value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,10))\n",
    "ax.set_xscale(\"log\",basex=2)\n",
    "sns.barplot(x=\"value\",y=\"candidate\",hue=\"class\",data=sumByClass,ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sumByClass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step-wise selection\n",
    "\n",
    "This analysis is different because we will use a filtered dataset based on the results using the original, non-filtered dataset.\n",
    "\n",
    "Significant volatiles that are only detected in the whitefly *non-toxic* class are taken out from the original dataset. That is, their abundance in the *toxic* class should be equal to 0 (not detected in the toxic genotypes).\n",
    "\n",
    "Indeed, these volatiles are too discriminant between the two classes and thus these volatiles get a very high feature importance. As the goal of this analysis is also to get significant volatiles that are either present in both classes (but quantitatively different) or only detectable in the *toxic* class. \n",
    "\n",
    "**Which of the candidate have a value of 0 in the toxic class but a value > 0 in the non-toxic class?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates_to_drop = sumByClass[(sumByClass[\"class\"] == \"toxic\") & (sumByClass[\"value\"] == 0)][\"candidate\"].tolist()\n",
    "candidates_to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"pheno_terpenoids.tsv\",sep=\"\\t\",index_col=0)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the 3 volatiles with an abundance equal to zero in the toxic class\n",
    "df = df.drop(columns=candidates_to_drop)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define modified X and unmodified y arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get whitefly classes\n",
    "y = df[\"wf\"].tolist()\n",
    "stratify_info = df['wf'].map({'non-toxic': 0, 'toxic': 1})\n",
    "\n",
    "# get matrix X of volatile values\n",
    "X = df.iloc[:,2:]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import single_random_forest_run\n",
    "\n",
    "res = single_random_forest_run(X,y,disp=False,rs=1234,nb_of_splits=6,nb_of_trees=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfy = pd.DataFrame(y,columns=['tox'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
